{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd0bbb5-f644-438f-bff5-bda78f689316",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "\n",
    "In this homework, we'll take the ride duration prediction model that we deployed in batch mode in homework 4 and improve the reliability of our code with unit and integration tests.\n",
    "\n",
    "You'll find the starter code in the [homework][homework] directory.\n",
    "\n",
    "[homework]: https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/06-best-practices/homework\n",
    "\n",
    "## Q1. Refactoring\n",
    "\n",
    "Before we can start coverting our code with tests, we need to refactor it. We'll start by getting rid of all the global variables.\n",
    "\n",
    "* Let's create a function `main` with two parameters: `year` and `month`.\n",
    "* Move all the code (except `read_data`) inside `main`\n",
    "* Make `categorical` a parameter for `read_data` and pass it inside `main`\n",
    "\n",
    "Now we need to create the \"main\" block from which we'll invoke the main function. How does the `if` statement that we use for this looks like?\n",
    "\n",
    "Hint: after refactoring, check that the code still works. Just run it e.g. for Feb 2021 and see if it finishes successfully.\n",
    "\n",
    "To make it easier to run it, you can write results to your local filesystem. E.g. here:\n",
    "\n",
    "```\n",
    "output_file = f'taxi_type=fhv_year={year:04d}_month={month:02d}.parquet'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d69c96-cc14-4d21-ab7f-5f892213bde6",
   "metadata": {},
   "source": [
    "Answer: `if __name__ == '__main__':`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afa9d4-162b-4f8b-bbd2-2c40638650fd",
   "metadata": {},
   "source": [
    "# Q2. Installing pytest\n",
    "\n",
    "Now we need to install `pytest`:\n",
    "\n",
    "```\n",
    "pipenv install --dev pytest\n",
    "```\n",
    "\n",
    "Next, create a folder `tests` and create two files. One will be the file with tests. We can name it `test_batch.py`.\n",
    "\n",
    "What should be the other file?\n",
    "\n",
    "Hint: to be able to test `batch.py`, we need to be able to import it. Without this other file, we won't be able to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbf89e-717d-4d81-8314-17f2a3dc2bc2",
   "metadata": {},
   "source": [
    "Answer: `tests/__init__.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03b64c-de37-4284-a8f5-880a0c44c4b6",
   "metadata": {},
   "source": [
    "## Q3. Writing first unit test\n",
    "\n",
    "Now let's cover our code with unit tests.\n",
    "\n",
    "We'll start with the pre-processing logic inside `read_data`.\n",
    "\n",
    "It's difficult to test right now because first reads the file and then performs some transformations. We need to split this code into two parts: reading (I/O) and tranformation.\n",
    "\n",
    "So let's create a function `prepare_data` that takes in a dataframe (and some other parameters too) and applies some tranformation to it.\n",
    "\n",
    "(That's basically the entire `read_data` function after reading the parquet file)\n",
    "\n",
    "Now create a test and use this as input:\n",
    "\n",
    "```\n",
    "data = [\n",
    "    (None, None, dt(1, 2), dt(1, 10)),\n",
    "    (1, 1, dt(1, 2), dt(1, 10)),\n",
    "    (1, 1, dt(1, 2, 0), dt(1, 2, 50)),\n",
    "    (1, 1, dt(1, 2, 0), dt(2, 2, 1)),        \n",
    "]\n",
    "\n",
    "columns = ['PUlocationID', 'DOlocationID', 'pickup_datetime', 'dropOff_datetime']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "```\n",
    "\n",
    "Where `dt` is a helper function:\n",
    "\n",
    "```\n",
    "from datetime import datetime\n",
    "\n",
    "def dt(hour, minute, second=0):\n",
    "    return datetime(2021, 1, 1, hour, minute, second)\n",
    "```\n",
    "\n",
    "Define the expected output and use the assert to make sure that the actual dataframe matches the expected one\n",
    "\n",
    "Tip: When you compare two Pandas DataFrames, the result is also a DataFrame. The same is true for Pandas Series. Also, a DataFrame could be turned into a list of dictionaries.\n",
    "\n",
    "How many rows should be there in the expected dataframe?\n",
    "\n",
    "* 1\n",
    "* 2\n",
    "* 3\n",
    "* 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80f770-c982-47ea-b10d-d0c984dc1f27",
   "metadata": {},
   "source": [
    "Answer: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af02e4-677d-417c-a885-e205ce956e50",
   "metadata": {},
   "source": [
    "## Q4. Mocking S3 with Localstack\n",
    "\n",
    "Now let's prepare for an integration test. In our script, we write data to S3. So we'll use Localstack to mimic S3.\n",
    "\n",
    "First, let's run Localstack with Docker compose. Let's create a `docker-compose.yaml` file with just one service: localstack. Inside localstack, we're only interested in running S3.\n",
    "\n",
    "Start the service and test it by creating a bucket where we'll keep the output. Let's call it \"nyc-duration\".\n",
    "\n",
    "With AWS CLI, this is how we create a bucket:\n",
    "\n",
    "```\n",
    "aws s3 mb s3://nyc-duration\n",
    "```\n",
    "\n",
    "Adjust it for localstack. How does the command look like?\n",
    "\n",
    "Check that the bucket was successfully created. With AWS, this is how we typically do it:\n",
    "\n",
    "```\n",
    "aws s3 ls\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d743e30-a1c9-4105-9283-720b476b7d0e",
   "metadata": {},
   "source": [
    "Answer: awslocal s3 s3://nyc-duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9304b4-1268-4cf5-9da2-0775c8a73d12",
   "metadata": {},
   "source": [
    "### Make input and output paths configurable\n",
    "\n",
    "Right now the input and output paths are hardcoded, but we want to change it for the tests.\n",
    "\n",
    "One of the possible ways would be to specify `INPUT_FILE_PATTERN` and `OUTPUT_FILE_PATTERN` via the env variables. Let's do that:\n",
    "\n",
    "```\n",
    "export INPUT_FILE_PATTERN=\"s3://nyc-duration/in/{year:04d}-{month:02d}.parquet\"\n",
    "export OUTPUT_FILE_PATTERN=\"s3://nyc-duration/out/{year:04d}-{month:02d}.parquet\"\n",
    "```\n",
    "\n",
    "And this is how we can read them:\n",
    "\n",
    "```\n",
    "def get_input_path(year, month):\n",
    "    default_input_pattern = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/nyc-tlc/fhv/fhv_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "    input_pattern = os.getenv('INPUT_FILE_PATTERN', default_input_pattern)\n",
    "    return input_pattern.format(year=year, month=month)\n",
    "\n",
    "\n",
    "def get_output_path(year, month):\n",
    "    default_output_pattern = 's3://nyc-duration-prediction-alexey/taxi_type=fhv/year={year:04d}/month={month:02d}/predictions.parquet'\n",
    "    output_pattern = os.getenv('OUTPUT_FILE_PATTERN', default_output_pattern)\n",
    "    return output_pattern.format(year=year, month=month)\n",
    "\n",
    "\n",
    "def main(year, month):\n",
    "    input_file = get_input_path(year, month)\n",
    "    output_file = get_output_path(year, month)\n",
    "    # rest of the main function ... \n",
    "```\n",
    "\n",
    "### Reading from Localstack S3 with Pandas\n",
    "\n",
    "So far we've been reading parquet files from S3 with using pandas `read_parquet`. But this way we read it from the actual S3 service. Now we need to replace it with our localstack one.\n",
    "\n",
    "For that, we need to specify the endpoint url:\n",
    "\n",
    "```\n",
    "options = {\n",
    "    'client_kwargs': {\n",
    "        'endpoint_url': S3_ENDPOINT_URL\n",
    "    }\n",
    "}\n",
    "\n",
    "df = pd.read_parquet('s3://bucket/file.parquet', storage_options=options)\n",
    "```\n",
    "\n",
    "Let's modify our `read_data` function:\n",
    "\n",
    "* check if `S3_ENDPOINT_URL` is set, and if it is, use it for reading\n",
    "* otherwise use the usual way"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
